{
 "metadata": {
  "name": "",
  "signature": "sha256:668d3932273669aeb2ef46a46a7f004080100397d08e9fa6b28301326d4cacd8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##mrjob##\n",
      "\n",
      "__mrjob__ is a software package developed by the restaurant recommendation company _Yelp_. \n",
      "It's goal is to simplify the deployment of map-reduce jobs based on streaming and python onto different \n",
      "frameworks such as Hadoop on a private cluster or hadoop on AWS (called EMR).\n",
      "\n",
      "* You can read more about mrjob here: https://pythonhosted.org/mrjob/index.html  \n",
      "* and you can clone it from github here: https://github.com/yelp/mrjob\n",
      "\n",
      "In this notebook we run a simple word-count example, add to it some logging commands, and look at two modes of running the job."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "home_dir=os.environ['HOME']\n",
      "root_dir = '/Users/yoavfreund/BigData/mrjob'\n",
      "examples_dir=root_dir+'/examples/'\n",
      "examples_dir='/home/ubuntu/UCSD_BigData/notebooks/weather.mapreduce'\n",
      "!ls -l $examples_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 2940\r\n",
        "-rwxrwxr-x 1 ubuntu ubuntu     307 May 10 00:34 coding.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu     202 May 20 22:03 counts\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu    2506 May 10 00:34 Description of Assignment.ipynb\r\n",
        "-rwxrwxr-x 1 ubuntu ubuntu     723 May 10 00:34 Eigen-by-Station.sh\r\n",
        "-rwxrwxr-x 1 ubuntu ubuntu    1408 May 10 00:34 map-year-temp.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  112737 May 23 00:07 mrjob and EMR.ipynb\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu    1504 May 20 22:00 mr_weather.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu    1610 May 10 00:34 mr_word_freq_count.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu     698 May 10 00:34 README.txt\r\n",
        "-rwxrwxr-x 1 ubuntu ubuntu    1226 May 10 00:34 reduce-year-temp.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu 1833012 May 10 00:34 stations.pkl.gz\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu   39934 May 18 22:19 Stations_Statistics.ipynb\r\n",
        "-rwxrwxr-x 1 ubuntu ubuntu    5136 May 10 00:34 Statistics.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu   77711 May 11 23:48 weather_MRjob.ipynb\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  896040 May 22 23:45 weather_MRjob-with-utils.ipynb\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename=examples_dir+'mr_word_freq_count.py'\n",
      "print filename\n",
      "!ls $filaname\n",
      "# load example code from mr jobs as a starting point\n",
      "#%load  $filename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData/notebooks/weather.mapreducemr_word_freq_count.py\n",
        "coding.py\t\t\t README.txt\r\n",
        "counts\t\t\t\t reduce-year-temp.py\r\n",
        "Description of Assignment.ipynb  stations.pkl.gz\r\n",
        "Eigen-by-Station.sh\t\t Stations_Statistics.ipynb\r\n",
        "map-year-temp.py\t\t Statistics.py\r\n",
        "mrjob and EMR.ipynb\t\t weather_MRjob.ipynb\r\n",
        "mr_weather.py\t\t\t weather_MRjob-with-utils.ipynb\r\n",
        "mr_word_freq_count.py\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_word_freq_count.py\n",
      "#!/usr/bin/python\n",
      "# Copyright 2009-2010 Yelp\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\"\"\"The classic MapReduce job: count the frequency of words.\n",
      "\"\"\"\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "WORD_RE = re.compile(r\"[\\w']+\")\n",
      "\n",
      "#logfile=open('log','w')\n",
      "logfile=stderr\n",
      "\n",
      "class MRWordFreqCount(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        #for word in re.findall(WORD_RE,line):\n",
      "        for word in WORD_RE.findall(line):\n",
      "            logfile.write('mapper '+word.lower()+'\\n')\n",
      "            yield (word.lower(), 1)\n",
      "\n",
      "    def combiner(self, word, counts):\n",
      "        #yield (word, sum(counts))\n",
      "        l_counts=[c for c in counts]  # extract list from iterator\n",
      "        S=sum(l_counts)\n",
      "        logfile.write('combiner '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        yield (word, S)\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        #yield (word, sum(counts))\n",
      "        l_counts=[c for c in counts]  # extract list from iterator\n",
      "        S=sum(l_counts)\n",
      "        logfile.write('reducer '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        yield (word, S)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWordFreqCount.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting mr_word_freq_count.py\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_word_freq_count.py /home/ubuntu/UCSD_BigData/notebooks/weather.mapreduce/README.txt > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/mr_word_freq_count.ubuntu.20140523.003117.647258\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140523.003117.647258/step-0-mapper_part-00000\r\n",
        "mapper eigen\r\n",
        "mapper by\r\n",
        "mapper station\r\n",
        "mapper sh\r\n",
        "mapper the\r\n",
        "mapper master\r\n",
        "mapper shell\r\n",
        "mapper script\r\n",
        "mapper for\r\n",
        "mapper running\r\n",
        "mapper the\r\n",
        "mapper map\r\n",
        "mapper reduce\r\n",
        "mapper job\r\n",
        "mapper map\r\n",
        "mapper year\r\n",
        "mapper temp\r\n",
        "mapper py\r\n",
        "mapper the\r\n",
        "mapper map\r\n",
        "mapper script\r\n",
        "mapper reduce\r\n",
        "mapper year\r\n",
        "mapper temp\r\n",
        "mapper py\r\n",
        "mapper the\r\n",
        "mapper reduce\r\n",
        "mapper script\r\n",
        "mapper statistics\r\n",
        "mapper py\r\n",
        "mapper a\r\n",
        "mapper module\r\n",
        "mapper for\r\n",
        "mapper computing\r\n",
        "mapper first\r\n",
        "mapper and\r\n",
        "mapper second\r\n",
        "mapper order\r\n",
        "mapper statistics\r\n",
        "mapper coding\r\n",
        "mapper py\r\n",
        "mapper a\r\n",
        "mapper module\r\n",
        "mapper for\r\n",
        "mapper writing\r\n",
        "mapper and\r\n",
        "mapper reading\r\n",
        "mapper key\r\n",
        "mapper value\r\n",
        "mapper lines\r\n",
        "mapper where\r\n",
        "mapper the\r\n",
        "mapper value\r\n",
        "mapper is\r\n",
        "mapper a\r\n",
        "mapper pickled\r\n",
        "mapper encoded\r\n",
        "mapper object\r\n",
        "mapper process\r\n",
        "mapper days\r\n",
        "mapper py\r\n",
        "mapper a\r\n",
        "mapper script\r\n",
        "mapper for\r\n",
        "mapper generating\r\n",
        "mapper dates\r\n",
        "mapper pkl\r\n",
        "mapper a\r\n",
        "mapper table\r\n",
        "mapper that\r\n",
        "mapper related\r\n",
        "mapper dates\r\n",
        "mapper of\r\n",
        "mapper the\r\n",
        "mapper form\r\n",
        "mapper mm\r\n",
        "mapper dd\r\n",
        "mapper to\r\n",
        "mapper numbers\r\n",
        "mapper in\r\n",
        "mapper the\r\n",
        "mapper range\r\n",
        "mapper 0\r\n",
        "mapper 365\r\n",
        "mapper dates\r\n",
        "mapper pkl\r\n",
        "mapper process\r\n",
        "mapper stations\r\n",
        "mapper py\r\n",
        "mapper a\r\n",
        "mapper script\r\n",
        "mapper which\r\n",
        "mapper generates\r\n",
        "mapper stat2lat\r\n",
        "mapper pkl\r\n",
        "mapper a\r\n",
        "mapper table\r\n",
        "mapper that\r\n",
        "mapper relates\r\n",
        "mapper station\r\n",
        "mapper names\r\n",
        "mapper to\r\n",
        "mapper their\r\n",
        "mapper latitude\r\n",
        "mapper stat2lat\r\n",
        "mapper pkl\r\n",
        "mapper randomize\r\n",
        "mapper py\r\n",
        "mapper a\r\n",
        "mapper script\r\n",
        "mapper for\r\n",
        "mapper efficiently\r\n",
        "mapper randomizing\r\n",
        "mapper the\r\n",
        "mapper order\r\n",
        "mapper of\r\n",
        "mapper lines\r\n",
        "mapper in\r\n",
        "mapper a\r\n",
        "mapper file\r\n",
        "mapper readme\r\n",
        "mapper txt\r\n",
        "mapper this\r\n",
        "mapper file\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "combiner 0 [1]=1\r\n",
        "combiner 365 [1]=1\r\n",
        "combiner a [1,1,1,1,1,1,1,1,1]=9\r\n",
        "combiner and [1,1]=2\r\n",
        "combiner by [1]=1\r\n",
        "combiner coding [1]=1\r\n",
        "combiner computing [1]=1\r\n",
        "combiner dates [1,1,1]=3\r\n",
        "combiner days [1]=1\r\n",
        "combiner dd [1]=1\r\n",
        "combiner efficiently [1]=1\r\n",
        "combiner eigen [1]=1\r\n",
        "combiner encoded [1]=1\r\n",
        "combiner file [1,1]=2\r\n",
        "combiner first [1]=1\r\n",
        "combiner for [1,1,1,1,1]=5\r\n",
        "combiner form [1]=1\r\n",
        "combiner generates [1]=1\r\n",
        "combiner generating [1]=1\r\n",
        "combiner in [1,1]=2\r\n",
        "combiner is [1]=1\r\n",
        "combiner job [1]=1\r\n",
        "combiner key [1]=1\r\n",
        "combiner latitude [1]=1\r\n",
        "combiner lines [1,1]=2\r\n",
        "combiner map [1,1,1]=3\r\n",
        "combiner master [1]=1\r\n",
        "combiner mm [1]=1\r\n",
        "combiner module [1,1]=2\r\n",
        "combiner names [1]=1\r\n",
        "combiner numbers [1]=1\r\n",
        "combiner object [1]=1\r\n",
        "combiner of [1,1]=2\r\n",
        "combiner order [1,1]=2\r\n",
        "combiner pickled [1]=1\r\n",
        "combiner pkl [1,1,1,1]=4\r\n",
        "combiner process [1,1]=2\r\n",
        "combiner py [1,1,1,1,1,1,1]=7\r\n",
        "combiner randomize [1]=1\r\n",
        "combiner randomizing [1]=1\r\n",
        "combiner range [1]=1\r\n",
        "combiner reading [1]=1\r\n",
        "combiner readme [1]=1\r\n",
        "combiner reduce [1,1,1]=3\r\n",
        "combiner related [1]=1\r\n",
        "combiner relates [1]=1\r\n",
        "combiner running [1]=1\r\n",
        "combiner script [1,1,1,1,1,1]=6\r\n",
        "combiner second [1]=1\r\n",
        "combiner sh [1]=1\r\n",
        "combiner shell [1]=1\r\n",
        "combiner stat2lat [1,1]=2\r\n",
        "combiner station [1,1]=2\r\n",
        "combiner stations [1]=1\r\n",
        "combiner statistics [1,1]=2\r\n",
        "combiner table [1,1]=2\r\n",
        "combiner temp [1,1]=2\r\n",
        "combiner that [1,1]=2\r\n",
        "combiner the [1,1,1,1,1,1,1,1]=8\r\n",
        "combiner their [1]=1\r\n",
        "combiner this [1]=1\r\n",
        "combiner to [1,1]=2\r\n",
        "combiner txt [1]=1\r\n",
        "combiner value [1,1]=2\r\n",
        "combiner where [1]=1\r\n",
        "combiner which [1]=1\r\n",
        "combiner writing [1]=1\r\n",
        "combiner year [1,1]=2\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140523.003117.647258/step-0-mapper-sorted\r\n",
        "> sort /tmp/mr_word_freq_count.ubuntu.20140523.003117.647258/step-0-mapper_part-00000\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140523.003117.647258/step-0-reducer_part-00000\r\n",
        "reducer 0 [1]=1\r\n",
        "reducer 365 [1]=1\r\n",
        "reducer a [9]=9\r\n",
        "reducer and [2]=2\r\n",
        "reducer by [1]=1\r\n",
        "reducer coding [1]=1\r\n",
        "reducer computing [1]=1\r\n",
        "reducer dates [3]=3\r\n",
        "reducer days [1]=1\r\n",
        "reducer dd [1]=1\r\n",
        "reducer efficiently [1]=1\r\n",
        "reducer eigen [1]=1\r\n",
        "reducer encoded [1]=1\r\n",
        "reducer file [2]=2\r\n",
        "reducer first [1]=1\r\n",
        "reducer for [5]=5\r\n",
        "reducer form [1]=1\r\n",
        "reducer generates [1]=1\r\n",
        "reducer generating [1]=1\r\n",
        "reducer in [2]=2\r\n",
        "reducer is [1]=1\r\n",
        "reducer job [1]=1\r\n",
        "reducer key [1]=1\r\n",
        "reducer latitude [1]=1\r\n",
        "reducer lines [2]=2\r\n",
        "reducer map [3]=3\r\n",
        "reducer master [1]=1\r\n",
        "reducer mm [1]=1\r\n",
        "reducer module [2]=2\r\n",
        "reducer names [1]=1\r\n",
        "reducer numbers [1]=1\r\n",
        "reducer object [1]=1\r\n",
        "reducer of [2]=2\r\n",
        "reducer order [2]=2\r\n",
        "reducer pickled [1]=1\r\n",
        "reducer pkl [4]=4\r\n",
        "reducer process [2]=2\r\n",
        "reducer py [7]=7\r\n",
        "reducer randomize [1]=1\r\n",
        "reducer randomizing [1]=1\r\n",
        "reducer range [1]=1\r\n",
        "reducer reading [1]=1\r\n",
        "reducer readme [1]=1\r\n",
        "reducer reduce [3]=3\r\n",
        "reducer related [1]=1\r\n",
        "reducer relates [1]=1\r\n",
        "reducer running [1]=1\r\n",
        "reducer script [6]=6\r\n",
        "reducer second [1]=1\r\n",
        "reducer sh [1]=1\r\n",
        "reducer shell [1]=1\r\n",
        "reducer stat2lat [2]=2\r\n",
        "reducer station [2]=2\r\n",
        "reducer stations [1]=1\r\n",
        "reducer statistics [2]=2\r\n",
        "reducer table [2]=2\r\n",
        "reducer temp [2]=2\r\n",
        "reducer that [2]=2\r\n",
        "reducer the [8]=8\r\n",
        "reducer their [1]=1\r\n",
        "reducer this [1]=1\r\n",
        "reducer to [2]=2\r\n",
        "reducer txt [1]=1\r\n",
        "reducer value [2]=2\r\n",
        "reducer where [1]=1\r\n",
        "reducer which [1]=1\r\n",
        "reducer writing [1]=1\r\n",
        "reducer year [2]=2\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Moving /tmp/mr_word_freq_count.ubuntu.20140523.003117.647258/step-0-reducer_part-00000 -> /tmp/mr_word_freq_count.ubuntu.20140523.003117.647258/output/part-00000\r\n",
        "Streaming final output from /tmp/mr_word_freq_count.ubuntu.20140523.003117.647258/output\r\n",
        "removing tmp directory /tmp/mr_word_freq_count.ubuntu.20140523.003117.647258\r\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat log"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cat: log: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"0\"\t1\r\n",
        "\"365\"\t1\r\n",
        "\"a\"\t9\r\n",
        "\"and\"\t2\r\n",
        "\"by\"\t1\r\n",
        "\"coding\"\t1\r\n",
        "\"computing\"\t1\r\n",
        "\"dates\"\t3\r\n",
        "\"days\"\t1\r\n",
        "\"dd\"\t1\r\n",
        "\"efficiently\"\t1\r\n",
        "\"eigen\"\t1\r\n",
        "\"encoded\"\t1\r\n",
        "\"file\"\t2\r\n",
        "\"first\"\t1\r\n",
        "\"for\"\t5\r\n",
        "\"form\"\t1\r\n",
        "\"generates\"\t1\r\n",
        "\"generating\"\t1\r\n",
        "\"in\"\t2\r\n",
        "\"is\"\t1\r\n",
        "\"job\"\t1\r\n",
        "\"key\"\t1\r\n",
        "\"latitude\"\t1\r\n",
        "\"lines\"\t2\r\n",
        "\"map\"\t3\r\n",
        "\"master\"\t1\r\n",
        "\"mm\"\t1\r\n",
        "\"module\"\t2\r\n",
        "\"names\"\t1\r\n",
        "\"numbers\"\t1\r\n",
        "\"object\"\t1\r\n",
        "\"of\"\t2\r\n",
        "\"order\"\t2\r\n",
        "\"pickled\"\t1\r\n",
        "\"pkl\"\t4\r\n",
        "\"process\"\t2\r\n",
        "\"py\"\t7\r\n",
        "\"randomize\"\t1\r\n",
        "\"randomizing\"\t1\r\n",
        "\"range\"\t1\r\n",
        "\"reading\"\t1\r\n",
        "\"readme\"\t1\r\n",
        "\"reduce\"\t3\r\n",
        "\"related\"\t1\r\n",
        "\"relates\"\t1\r\n",
        "\"running\"\t1\r\n",
        "\"script\"\t6\r\n",
        "\"second\"\t1\r\n",
        "\"sh\"\t1\r\n",
        "\"shell\"\t1\r\n",
        "\"stat2lat\"\t2\r\n",
        "\"station\"\t2\r\n",
        "\"stations\"\t1\r\n",
        "\"statistics\"\t2\r\n",
        "\"table\"\t2\r\n",
        "\"temp\"\t2\r\n",
        "\"that\"\t2\r\n",
        "\"the\"\t8\r\n",
        "\"their\"\t1\r\n",
        "\"this\"\t1\r\n",
        "\"to\"\t2\r\n",
        "\"txt\"\t1\r\n",
        "\"value\"\t2\r\n",
        "\"where\"\t1\r\n",
        "\"which\"\t1\r\n",
        "\"writing\"\t1\r\n",
        "\"year\"\t2\r\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Different modes of running a mrjob map-reduce job ##\n",
      "\n",
      "Once the mapper, combiner and reducer have been written and tested, you can run the job on different types of infrastructure:\n",
      "\n",
      "1. __inline__ run the job as a single process on the local machine.\n",
      "1. __local__ run the job on the local machine, but using multiple processes to simulate parallel processing.\n",
      "1. __hadoop__ run the job on a hadoop cluster (such as the one we have in SDSC)\n",
      "1. __EMR__ (Elastic Map Reduce) run the job on a hadoop cluster running on the amazon cloud.\n",
      "\n",
      "Below we run the same process we ran at the top using __local__ instead of the default __inline__. Observe that in this case the reducers have some non-trivial work to do even when combiners are used."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running in local mode"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_word_freq_count.py --runner=local /home/ubuntu/UCSD_BigData/notebooks/weather.mapreduce/README.txt > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing to /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-mapper_part-00000\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --mapper /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/input_part-00000 | sort | /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --combiner > /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing to /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-mapper_part-00001\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --mapper /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/input_part-00001 | sort | /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --combiner > /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-mapper_part-00001\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "STDERR: mapper eigen\r\n",
        "STDERR: mapper by\r\n",
        "STDERR: mapper station\r\n",
        "STDERR: mapper sh\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper master\r\n",
        "STDERR: mapper shell\r\n",
        "STDERR: mapper script\r\n",
        "STDERR: mapper for\r\n",
        "STDERR: mapper running\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper map\r\n",
        "STDERR: mapper reduce\r\n",
        "STDERR: mapper job\r\n",
        "STDERR: mapper map\r\n",
        "STDERR: mapper year\r\n",
        "STDERR: mapper temp\r\n",
        "STDERR: mapper py\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper map\r\n",
        "STDERR: mapper script\r\n",
        "STDERR: mapper reduce\r\n",
        "STDERR: mapper year\r\n",
        "STDERR: mapper temp\r\n",
        "STDERR: mapper py\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper reduce\r\n",
        "STDERR: mapper script\r\n",
        "STDERR: mapper statistics\r\n",
        "STDERR: mapper py\r\n",
        "STDERR: mapper a\r\n",
        "STDERR: mapper module\r\n",
        "STDERR: mapper for\r\n",
        "STDERR: mapper computing\r\n",
        "STDERR: mapper first\r\n",
        "STDERR: mapper and\r\n",
        "STDERR: mapper second\r\n",
        "STDERR: mapper order\r\n",
        "STDERR: mapper statistics\r\n",
        "STDERR: mapper coding\r\n",
        "STDERR: mapper py\r\n",
        "STDERR: mapper a\r\n",
        "STDERR: mapper module\r\n",
        "STDERR: mapper for\r\n",
        "STDERR: mapper writing\r\n",
        "STDERR: mapper and\r\n",
        "STDERR: mapper reading\r\n",
        "STDERR: mapper key\r\n",
        "STDERR: mapper value\r\n",
        "STDERR: mapper lines\r\n",
        "STDERR: mapper where\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper value\r\n",
        "STDERR: mapper is\r\n",
        "STDERR: mapper a\r\n",
        "STDERR: mapper pickled\r\n",
        "STDERR: mapper encoded\r\n",
        "STDERR: mapper object\r\n",
        "STDERR: mapper process\r\n",
        "STDERR: mapper days\r\n",
        "STDERR: mapper py\r\n",
        "STDERR: mapper a\r\n",
        "STDERR: mapper script\r\n",
        "STDERR: mapper for\r\n",
        "STDERR: mapper generating\r\n",
        "STDERR: mapper dates\r\n",
        "STDERR: mapper pkl\r\n",
        "STDERR: mapper a\r\n",
        "STDERR: mapper table\r\n",
        "STDERR: mapper that\r\n",
        "STDERR: mapper related\r\n",
        "STDERR: mapper dates\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "STDERR: combiner a [1,1,1,1,1]=5\r\n",
        "STDERR: combiner and [1,1]=2\r\n",
        "STDERR: combiner by [1]=1\r\n",
        "STDERR: combiner coding [1]=1\r\n",
        "STDERR: combiner computing [1]=1\r\n",
        "STDERR: combiner dates [1,1]=2\r\n",
        "STDERR: combiner days [1]=1\r\n",
        "STDERR: combiner eigen [1]=1\r\n",
        "STDERR: combiner encoded [1]=1\r\n",
        "STDERR: combiner first [1]=1\r\n",
        "STDERR: combiner for [1,1,1,1]=4\r\n",
        "STDERR: combiner generating [1]=1\r\n",
        "STDERR: combiner is [1]=1\r\n",
        "STDERR: combiner job [1]=1\r\n",
        "STDERR: combiner key [1]=1\r\n",
        "STDERR: combiner lines [1]=1\r\n",
        "STDERR: combiner map [1,1,1]=3\r\n",
        "STDERR: combiner master [1]=1\r\n",
        "STDERR: combiner module [1,1]=2\r\n",
        "STDERR: combiner object [1]=1\r\n",
        "STDERR: combiner order [1]=1\r\n",
        "STDERR: combiner pickled [1]=1\r\n",
        "STDERR: combiner pkl [1]=1\r\n",
        "STDERR: combiner process [1]=1\r\n",
        "STDERR: combiner py [1,1,1,1,1]=5\r\n",
        "STDERR: combiner reading [1]=1\r\n",
        "STDERR: combiner reduce [1,1,1]=3\r\n",
        "STDERR: combiner related [1]=1\r\n",
        "STDERR: combiner running [1]=1\r\n",
        "STDERR: combiner script [1,1,1,1]=4\r\n",
        "STDERR: combiner second [1]=1\r\n",
        "STDERR: combiner sh [1]=1\r\n",
        "STDERR: combiner shell [1]=1\r\n",
        "STDERR: combiner station [1]=1\r\n",
        "STDERR: combiner statistics [1,1]=2\r\n",
        "STDERR: combiner table [1]=1\r\n",
        "STDERR: combiner temp [1,1]=2\r\n",
        "STDERR: combiner that [1]=1\r\n",
        "STDERR: combiner the [1,1,1,1,1]=5\r\n",
        "STDERR: combiner value [1,1]=2\r\n",
        "STDERR: combiner where [1]=1\r\n",
        "STDERR: combiner writing [1]=1\r\n",
        "STDERR: combiner year [1,1]=2\r\n",
        "STDERR: mapper of\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper form\r\n",
        "STDERR: mapper mm\r\n",
        "STDERR: mapper dd\r\n",
        "STDERR: mapper to\r\n",
        "STDERR: mapper numbers\r\n",
        "STDERR: mapper in\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper range\r\n",
        "STDERR: mapper 0\r\n",
        "STDERR: mapper 365\r\n",
        "STDERR: mapper dates\r\n",
        "STDERR: mapper pkl\r\n",
        "STDERR: mapper process\r\n",
        "STDERR: mapper stations\r\n",
        "STDERR: mapper py\r\n",
        "STDERR: mapper a\r\n",
        "STDERR: mapper script\r\n",
        "STDERR: mapper which\r\n",
        "STDERR: mapper generates\r\n",
        "STDERR: mapper stat2lat\r\n",
        "STDERR: mapper pkl\r\n",
        "STDERR: mapper a\r\n",
        "STDERR: mapper table\r\n",
        "STDERR: mapper that\r\n",
        "STDERR: mapper relates\r\n",
        "STDERR: mapper station\r\n",
        "STDERR: mapper names\r\n",
        "STDERR: mapper to\r\n",
        "STDERR: mapper their\r\n",
        "STDERR: mapper latitude\r\n",
        "STDERR: mapper stat2lat\r\n",
        "STDERR: mapper pkl\r\n",
        "STDERR: mapper randomize\r\n",
        "STDERR: mapper py\r\n",
        "STDERR: mapper a\r\n",
        "STDERR: mapper script\r\n",
        "STDERR: mapper for\r\n",
        "STDERR: mapper efficiently\r\n",
        "STDERR: mapper randomizing\r\n",
        "STDERR: mapper the\r\n",
        "STDERR: mapper order\r\n",
        "STDERR: mapper of\r\n",
        "STDERR: mapper lines\r\n",
        "STDERR: mapper in\r\n",
        "STDERR: mapper a\r\n",
        "STDERR: mapper file\r\n",
        "STDERR: mapper readme\r\n",
        "STDERR: mapper txt\r\n",
        "STDERR: mapper this\r\n",
        "STDERR: mapper file\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "STDERR: combiner 0 [1]=1\r\n",
        "STDERR: combiner 365 [1]=1\r\n",
        "STDERR: combiner a [1,1,1,1]=4\r\n",
        "STDERR: combiner dates [1]=1\r\n",
        "STDERR: combiner dd [1]=1\r\n",
        "STDERR: combiner efficiently [1]=1\r\n",
        "STDERR: combiner file [1,1]=2\r\n",
        "STDERR: combiner for [1]=1\r\n",
        "STDERR: combiner form [1]=1\r\n",
        "STDERR: combiner generates [1]=1\r\n",
        "STDERR: combiner in [1,1]=2\r\n",
        "STDERR: combiner latitude [1]=1\r\n",
        "STDERR: combiner lines [1]=1\r\n",
        "STDERR: combiner mm [1]=1\r\n",
        "STDERR: combiner names [1]=1\r\n",
        "STDERR: combiner numbers [1]=1\r\n",
        "STDERR: combiner of [1,1]=2\r\n",
        "STDERR: combiner order [1]=1\r\n",
        "STDERR: combiner pkl [1,1,1]=3\r\n",
        "STDERR: combiner process [1]=1\r\n",
        "STDERR: combiner py [1,1]=2\r\n",
        "STDERR: combiner randomize [1]=1\r\n",
        "STDERR: combiner randomizing [1]=1\r\n",
        "STDERR: combiner range [1]=1\r\n",
        "STDERR: combiner readme [1]=1\r\n",
        "STDERR: combiner relates [1]=1\r\n",
        "STDERR: combiner script [1,1]=2\r\n",
        "STDERR: combiner stat2lat [1,1]=2\r\n",
        "STDERR: combiner station [1]=1\r\n",
        "STDERR: combiner stations [1]=1\r\n",
        "STDERR: combiner table [1]=1\r\n",
        "STDERR: combiner that [1]=1\r\n",
        "STDERR: combiner the [1,1,1]=3\r\n",
        "STDERR: combiner their [1]=1\r\n",
        "STDERR: combiner this [1]=1\r\n",
        "STDERR: combiner to [1,1]=2\r\n",
        "STDERR: combiner txt [1]=1\r\n",
        "STDERR: combiner which [1]=1\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-mapper-sorted\r\n",
        "> sort /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-mapper_part-00000 /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-mapper_part-00001\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-reducer_part-00000\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --reducer /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/input_part-00000 > /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-reducer_part-00000\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-reducer_part-00001\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --reducer /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/input_part-00001 > /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-reducer_part-00001\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "STDERR: reducer 0 [1]=1\r\n",
        "STDERR: reducer 365 [1]=1\r\n",
        "STDERR: reducer a [4,5]=9\r\n",
        "STDERR: reducer and [2]=2\r\n",
        "STDERR: reducer by [1]=1\r\n",
        "STDERR: reducer coding [1]=1\r\n",
        "STDERR: reducer computing [1]=1\r\n",
        "STDERR: reducer dates [1,2]=3\r\n",
        "STDERR: reducer days [1]=1\r\n",
        "STDERR: reducer dd [1]=1\r\n",
        "STDERR: reducer efficiently [1]=1\r\n",
        "STDERR: reducer eigen [1]=1\r\n",
        "STDERR: reducer encoded [1]=1\r\n",
        "STDERR: reducer file [2]=2\r\n",
        "STDERR: reducer first [1]=1\r\n",
        "STDERR: reducer for [1,4]=5\r\n",
        "STDERR: reducer form [1]=1\r\n",
        "STDERR: reducer generates [1]=1\r\n",
        "STDERR: reducer generating [1]=1\r\n",
        "STDERR: reducer in [2]=2\r\n",
        "STDERR: reducer is [1]=1\r\n",
        "STDERR: reducer job [1]=1\r\n",
        "STDERR: reducer key [1]=1\r\n",
        "STDERR: reducer latitude [1]=1\r\n",
        "STDERR: reducer lines [1,1]=2\r\n",
        "STDERR: reducer map [3]=3\r\n",
        "STDERR: reducer master [1]=1\r\n",
        "STDERR: reducer mm [1]=1\r\n",
        "STDERR: reducer module [2]=2\r\n",
        "STDERR: reducer names [1]=1\r\n",
        "STDERR: reducer numbers [1]=1\r\n",
        "STDERR: reducer object [1]=1\r\n",
        "STDERR: reducer of [2]=2\r\n",
        "STDERR: reducer order [1,1]=2\r\n",
        "STDERR: reducer pickled [1]=1\r\n",
        "STDERR: reducer pkl [1,3]=4\r\n",
        "STDERR: reducer process [1,1]=2\r\n",
        "STDERR: reducer py [2,5]=7\r\n",
        "STDERR: reducer randomize [1]=1\r\n",
        "STDERR: reducer randomizing [1]=1\r\n",
        "STDERR: reducer range [1]=1\r\n",
        "STDERR: reducer reading [1]=1\r\n",
        "STDERR: reducer readme [1]=1\r\n",
        "STDERR: reducer reduce [3]=3\r\n",
        "STDERR: reducer related [1]=1\r\n",
        "STDERR: reducer relates [1]=1\r\n",
        "STDERR: reducer running [1]=1\r\n",
        "STDERR: reducer script [2,4]=6\r\n",
        "STDERR: reducer second [1]=1\r\n",
        "STDERR: reducer sh [1]=1\r\n",
        "STDERR: reducer shell [1]=1\r\n",
        "STDERR: reducer stat2lat [2]=2\r\n",
        "STDERR: reducer station [1,1]=2\r\n",
        "STDERR: reducer stations [1]=1\r\n",
        "STDERR: reducer statistics [2]=2\r\n",
        "STDERR: reducer table [1,1]=2\r\n",
        "STDERR: reducer temp [2]=2\r\n",
        "STDERR: reducer that [1,1]=2\r\n",
        "STDERR: reducer the [3,5]=8\r\n",
        "STDERR: reducer their [1]=1\r\n",
        "STDERR: reducer this [1]=1\r\n",
        "STDERR: reducer to [2]=2\r\n",
        "STDERR: reducer txt [1]=1\r\n",
        "STDERR: reducer value [2]=2\r\n",
        "STDERR: reducer where [1]=1\r\n",
        "STDERR: reducer which [1]=1\r\n",
        "STDERR: reducer writing [1]=1\r\n",
        "STDERR: reducer year [2]=2\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Moving /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-reducer_part-00000 -> /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/output/part-00000\r\n",
        "Moving /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/step-0-reducer_part-00001 -> /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/output/part-00001\r\n",
        "Streaming final output from /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112/output\r\n",
        "removing tmp directory /tmp/mr_word_freq_count.ubuntu.20140523.003335.503112\r\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"py\"\t7\r\n",
        "\"randomize\"\t1\r\n",
        "\"randomizing\"\t1\r\n",
        "\"range\"\t1\r\n",
        "\"reading\"\t1\r\n",
        "\"readme\"\t1\r\n",
        "\"reduce\"\t3\r\n",
        "\"related\"\t1\r\n",
        "\"relates\"\t1\r\n",
        "\"running\"\t1\r\n",
        "\"script\"\t6\r\n",
        "\"second\"\t1\r\n",
        "\"sh\"\t1\r\n",
        "\"shell\"\t1\r\n",
        "\"stat2lat\"\t2\r\n",
        "\"station\"\t2\r\n",
        "\"stations\"\t1\r\n",
        "\"statistics\"\t2\r\n",
        "\"table\"\t2\r\n",
        "\"temp\"\t2\r\n",
        "\"that\"\t2\r\n",
        "\"the\"\t8\r\n",
        "\"their\"\t1\r\n",
        "\"this\"\t1\r\n",
        "\"to\"\t2\r\n",
        "\"txt\"\t1\r\n",
        "\"value\"\t2\r\n",
        "\"where\"\t1\r\n",
        "\"which\"\t1\r\n",
        "\"writing\"\t1\r\n",
        "\"year\"\t2\r\n",
        "\"0\"\t1\r\n",
        "\"365\"\t1\r\n",
        "\"a\"\t9\r\n",
        "\"and\"\t2\r\n",
        "\"by\"\t1\r\n",
        "\"coding\"\t1\r\n",
        "\"computing\"\t1\r\n",
        "\"dates\"\t3\r\n",
        "\"days\"\t1\r\n",
        "\"dd\"\t1\r\n",
        "\"efficiently\"\t1\r\n",
        "\"eigen\"\t1\r\n",
        "\"encoded\"\t1\r\n",
        "\"file\"\t2\r\n",
        "\"first\"\t1\r\n",
        "\"for\"\t5\r\n",
        "\"form\"\t1\r\n",
        "\"generates\"\t1\r\n",
        "\"generating\"\t1\r\n",
        "\"in\"\t2\r\n",
        "\"is\"\t1\r\n",
        "\"job\"\t1\r\n",
        "\"key\"\t1\r\n",
        "\"latitude\"\t1\r\n",
        "\"lines\"\t2\r\n",
        "\"map\"\t3\r\n",
        "\"master\"\t1\r\n",
        "\"mm\"\t1\r\n",
        "\"module\"\t2\r\n",
        "\"names\"\t1\r\n",
        "\"numbers\"\t1\r\n",
        "\"object\"\t1\r\n",
        "\"of\"\t2\r\n",
        "\"order\"\t2\r\n",
        "\"pickled\"\t1\r\n",
        "\"pkl\"\t4\r\n",
        "\"process\"\t2\r\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running in EMR mode on a dedicated job flow"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_word_freq_count.py -r emr /home/ubuntu/UCSD_BigData/notebooks/weather.mapreduce/README.txt > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/mr_word_freq_count.ubuntu.20140523.003532.649405\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing master bootstrap script to /tmp/mr_word_freq_count.ubuntu.20140523.003532.649405/b.py\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://weiwei.bucket/scratch/mr_word_freq_count.ubuntu.20140523.003532.649405/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating Elastic MapReduce job flow\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job flow created with ID: j-2FGCC43JFFI15\r\n",
        "Created new job flow j-2FGCC43JFFI15\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 30.1s ago, status STARTING: Provisioning Amazon EC2 capacity\r\n"
       ]
      }
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running in EMR mode on existing job flow (hadoop cluster)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id='j-1HFD8T7K9LGVH'\n",
      "conf_file='/Users/yoavfreund/BigData/mrjob/cluster_configuration/Student_Config'\n",
      "!python mr_word_freq_count.py -r emr -c $conf_file --emr-job-flow-id=$job_flow_id /home/ubuntu/UCSD_BigData/notebooks/weather.mapreduce/README.txt > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traceback (most recent call last):\r\n",
        "  File \"mr_word_freq_count.py\", line 48, in <module>\r\n",
        "    MRWordFreqCount.run()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 494, in run\r\n",
        "    mr_job.execute()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 512, in execute\r\n",
        "    super(MRJob, self).execute()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 147, in execute\r\n",
        "    self.run_job()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 207, in run_job\r\n",
        "    with self.make_runner() as runner:\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 535, in make_runner\r\n",
        "    return super(MRJob, self).make_runner()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 162, in make_runner\r\n",
        "    return EMRJobRunner(**self.emr_job_runner_kwargs())\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/emr.py\", line 579, in __init__\r\n",
        "    self._fix_s3_scratch_and_log_uri_opts()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/emr.py\", line 668, in _fix_s3_scratch_and_log_uri_opts\r\n",
        "    bucket_loc = s3_conn.get_bucket(bucket_name).get_location()\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/mrjob/retry.py\", line 148, in call_and_maybe_retry\r\n",
        "    return f(*args, **kwargs)\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/boto/s3/connection.py\", line 471, in get_bucket\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    return self.head_bucket(bucket_name, headers=headers)\r\n",
        "  File \"//anaconda/lib/python2.7/site-packages/boto/s3/connection.py\", line 504, in head_bucket\r\n",
        "    raise err\r\n",
        "boto.exception.S3ResponseError: S3ResponseError: 403 Forbidden\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -l counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-r--r--  1 yoavfreund  staff  2726 May  9 07:55 counts\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}